kafka-
  A database that is storing, processing, and reacting infinte streams of data - a Pub/Sub stream data platform
  
  1. Like Hadoop - but Kafka stores continuous stream 
    whereas Hadoop stores big-batch of the files and process them on scheduled batches
    
  2. Enterprise Messaging - It is unified,elastic, cloud ready and modelled on distributed foundation systems
      
  3. Evolution of ETL and intergration-
    Any channels of input can source data/event to Kafka
    
    
    Example -
      A self driving car - ingress data from different cameras and sensors
       egress - the predictive actions
       
      Fraud detection systems
      E-com recommendation systems
      Log monitoring
      
      
  Kafka considers each action as event and such we have stream of events
  
       
-----------------
Application to Cloud-
  Rather than having point to point connections b/w the public and on-premise cloud
  we have a bridge as a Kafka that publishes the streams on both sides
  
  . This helps in maintaining
  . Sync data
  . All this is real-time as part of event stream
  . Scalable with Kafka clustures
  . Huge storage as if connection is down or backpressure to be implemented
  
------------------
Apache kafka

Kafka Connect-
  ingest from RDBMS, Mainframe, IoT ...
  Consumers as Hadoop, NoSQL, data stores, Object storages like S3
  Middleware integration b/w different API's
  
Kafka Streams-
  For embedded stream processing in applications like another library

Kafka Stream Interactive Query - 
  to retrieve state from Kafka i.e. monitoring
  
 ------------------
  Confluent OpenSS Kafka

Schema Registry - for data governance/quality
Connectors - drivers for different systems
REST proxy - 
------------------
Confluent Enterprise 

Control Center - for management, Graphical management and alerting
Replicator - Multi-data center replication between Kafka clustures
Auto databalancer - shifts data to create an even workload across the Kafka
Client Library: JMS messaging serive
And Enterprise support -



==================================
Components when discuss Kafka -

  Kafka clusture
  Producers - Serilalized 
  Consumers
  Brokers
  Message
  Topics - Named pipes/queues - Ordered collection []
  Zookeeper

Message in the topic are in the form of byte-array but 
  the typing contract is required which defines the format of message inside each topic
  
  - Each topic maintains the ordered collection of messages
  - Many producers can write to topic
  - Multiple consumers can read from topic
  
Kafka is a scalable middleware integration system, considering that problems to deal with-
 *) One broker may fail and all the data stored or topics may lost
 *) Huge load on a topic to be handled or Too much data that cannot be stored on one machine
 
 
 Solution:
 Partitioning Data ingestion:
 . Each partition contains the subset of the "Topic's messages"
 . Each partition is an "ordered" like queue, immutable log of messages
 
Partitions are distributed across brokers
*) Message key determines which partition a message is assigned to [Hashes the Key]
  - Consumer can override the Key at the time of Ingestion


==============================
Kafka Producers?
  Are the Channels/Programs that writes messages to Kafka Clusture/Broker/Partition
  - this can be done using the API's
  - Producers can be written in any Language as Drivers are available
  - native language of Kafka is Java
  - REST proxy provides that can also be used to send messasges
  - A CLI is available for debugging and testing purpose
  
  Partitioning Strategy? or I say it Loadbalancing b/w the Kafka paritions
    How Producer decides to choose Kafka Topic distributed amond Kafka Brokers in clusture
    
  How This is done?
    * Hash the key of Kafka message
    * Select the respective Parition for the hash
    * If Keys are not specified than default (Round robin fashion)
    
  Challenges or  Virtue?
    - The above partitioning strategy doesn't maintain the Order of Kafka messages
    - If Ordering is important than-
      Override the Partitioning strategy or Load balancing
      
      
    Note: By default, Each partition maintains the Order but Topics (doesn't maintain)
    
 ==================================
 
  Kafka Brokers?
    - Brokers receive messages and store messages when they are sent by the Producers
    - A Kafka cluster has multiple brokers
     - Each Broker has multiple partitions
     
  Note: Kafka is not a database 
  
  Kafka runs faster as the contract b/w Producer and Consumer is simple
  
 A typical architecture looks like---
  . Each Message in a Topic has been distributed across Partitions in Multiple brokers
  . A broker has multiple partitions 
  . Each partition has log files on the Broker disk to which it belongs to
    Properties of Logs?
      . Append only
      . Written data is immutable
      . Rolling file when size grows or based on the retention policy
            
  . Each message in the log is identified by its Offset'
    - Example a sequence number or monotonically increasing value
    
  . Each Broker has retention policy to manage log file growth (Default - 7 days)
  
  
  Benefit-
    . Each Consumer maintains it ReadOnly Offset to read the value from the logs files
    
 =============================
 
 Kafka Message?
  A segment which has been transferred by Broker using a partition
  This would be read and processed by Consumer later on.

Message Metadata?
  Key/value pair
  Offset
  Timestamp
  CompressionType
  
  
  |Offset.....|MessageSize.....|CRC...Magicbyte...Attributes...Timestamp....|KeyLength...KeyContent..ValueLength..ValueContent|
  
===============================
    12 Bytes                   =============================================
                                          6 or 14 Byte Header               ==================================================
                                                                                    Key/value pair(Bytes varies)

Magic Byte - Indicates the timestamp is present, which impacts the consumer


Fault Tolerant with Brokers?
  Replication - A typical replication factor is 3
    A lead broker and two follower that Keep standby copies and sync with the leader
    
  The Failover process has been handled by Kafka infrastructure does mean
  developer should not build that aspect in code
  

=========================================================

Kafka Consumers?
  A client program that polls the data from the Kafka Topics/partitions
  - A consumer subscribes to Kafka Topics in the clusture
  - Each consumer maintains its Offest irrespective of the Other Consumers
  - As each message written by Kafka on logs with a retention Policy
   . Consumers can change the offset to re-read messages
   
 - The consumer Offset is stored in a Kafka special topic, for the partition
 - A Consumer can be written in multiple languages
 - Also a CLI consumer is available to test, bebug Kafka setup
 
 
 * Deafult(Each consumer will receive all the message from the Topic)
 * Different Consumer can subscribe to same Topic
 * Consumer can create scalining group i.e. Consumer Groups
  where each Consumer is assinged to a subset of partitions of a topic
 
 
** How to handle Backpressure?
  * Using Consumer Groups - Dynamically adds or/ remove Consumers
  * Kafka store the messages as per the retention policy













 
 
 
 
 












