kafka-
  A database that is storing, processing, and reacting infinte streams of data - a Pub/Sub stream data platform
  
  1. Like Hadoop - but Kafka stores continuous stream 
    whereas Hadoop stores big-batch of the files and process them on scheduled batches
    
  2. Enterprise Messaging - It is unified,elastic, cloud ready and modelled on distributed foundation systems
      
  3. Evolution of ETL and intergration-
    Any channels of input can source data/event to Kafka
    
    
    Example -
      A self driving car - ingress data from different cameras and sensors
       egress - the predictive actions
       
      Fraud detection systems
      E-com recommendation systems
      Log monitoring
      
      
  Kafka considers each action as event and such we have stream of events
  
       
-----------------
Application to Cloud-
  Rather than having point to point connections b/w the public and on-premise cloud
  we have a bridge as a Kafka that publishes the streams on both sides
  
  . This helps in maintaining
  . Sync data
  . All this is real-time as part of event stream
  . Scalable with Kafka clustures
  . Huge storage as if connection is down or backpressure to be implemented
  
------------------
Apache kafka

Kafka Connect-
  ingest from RDBMS, Mainframe, IoT ...
  Consumers as Hadoop, NoSQL, data stores, Object storages like S3
  Middleware integration b/w different API's
  
Kafka Streams-
  For embedded stream processing in applications like another library

Kafka Stream Interactive Query - 
  to retrieve state from Kafka i.e. monitoring
  
 ------------------
  Confluent OpenSS Kafka

Schema Registry - for data governance/quality
Connectors - drivers for different systems
REST proxy - 
------------------
Confluent Enterprise 

Control Center - for management, Graphical management and alerting
Replicator - Multi-data center replication between Kafka clustures
Auto databalancer - shifts data to create an even workload across the Kafka
Client Library: JMS messaging serive
And Enterprise support -



==================================
Components when discuss Kafka -

  Kafka clusture
  Producers - Serilalized 
  Consumers
  Brokers
  Message
  Topics - Named pipes/queues - Ordered collection []
  Zookeeper

Message in the topic are in the form of byte-array but 
  the typing contract is required which defines the format of message inside each topic
  
  - Each topic maintains the ordered collection of messages
  - Many producers can write to topic
  - Multiple consumers can read from topic
  
Kafka is a scalable middleware integration system, considering that problems to deal with-
 *) One broker may fail and all the data stored or topics may lost
 *) Huge load on a topic to be handled or Too much data that cannot be stored on one machine
 
 
 Solution:
 Partitioning Data ingestion:
 . Each partition contains the subset of the "Topic's messages"
 . Each partition is an "ordered" like queue, immutable log of messages
 
Partitions are distributed across brokers
*) Message key determines which partition a message is assigned to [Hashes the Key]
  - Consumer can override the Key at the time of Ingestion


==============================
Kafka Producers?
  Are the Channels/Programs that writes messages to Kafka Clusture/Broker/Partition
  - this can be done using the API's
  - Producers can be written in any Language as Drivers are available
  - native language of Kafka is Java
  - REST proxy provides that can also be used to send messasges
  - A CLI is available for debugging and testing purpose
  
  Partitioning Strategy? or I say it Loadbalancing b/w the Kafka paritions
    How Producer decides to choose Kafka Topic distributed amond Kafka Brokers in clusture
    
  How This is done?
    * Hash the key of Kafka message
    * Select the respective Parition for the hash
    * If Keys are not specified than default (Round robin fashion)
    
  Challenges or  Virtue?
    - The above partitioning strategy doesn't maintain the Order of Kafka messages
    - If Ordering is important than-
      Override the Partitioning strategy or Load balancing
      
      
    Note: By default, Each partition maintains the Order but Topics (doesn't maintain)
    
 ==================================
 
  Kafka Brokers?
    - Brokers receive messages and store messages when they are sent by the Producers
    - A Kafka cluster has multiple brokers
     - Each Broker has multiple partitions
     
  Note: Kafka is not a database 
  
  Kafka runs faster as the contract b/w Producer and Consumer is simple
  
 A typical architecture looks like---
  . Each Message in a Topic has been distributed across Partitions in Multiple brokers
  . A broker has multiple partitions 
  . Each partition has log files on the Broker disk to which it belongs to
    Properties of Logs?
      . Append only
      . Written data is immutable
      . Rolling file when size grows or based on the retention policy
            
  . Each message in the log is identified by its Offset'
    - Example a sequence number or monotonically increasing value
    
  . Each Broker has retention policy to manage log file growth (Default - 7 days)
  
  
  Benefit-
    . Each Consumer maintains it ReadOnly Offset to read the value from the logs files
    
 =============================
 
 Kafka Message?
  A segment which has been transferred by Broker using a partition
  This would be read and processed by Consumer later on.

Message Metadata?
  Key/value pair
  Offset
  Timestamp
  CompressionType
  
  
  |Offset.....|MessageSize.....|CRC...Magicbyte...Attributes...Timestamp....|KeyLength...KeyContent..ValueLength..ValueContent|
  
===============================
    12 Bytes                   =============================================
                                          6 or 14 Byte Header               ==================================================
                                                                                    Key/value pair(Bytes varies)

Magic Byte - Indicates the timestamp is present, which impacts the consumer


Fault Tolerant with Brokers?
  Replication - A typical replication factor is 3
    A lead broker and two follower that Keep standby copies and sync with the leader
    
  The Failover process has been handled by Kafka infrastructure does mean
  developer should not build that aspect in code
  

=========================================================

Kafka Consumers?
  A client program that polls the data from the Kafka Topics/partitions
  - A consumer subscribes to Kafka Topics in the clusture
  - Each consumer maintains its Offest irrespective of the Other Consumers
  - As each message written by Kafka on logs with a retention Policy
   . Consumers can change the offset to re-read messages
   
 - The consumer Offset is stored in a Kafka special topic, for the partition
 - A Consumer can be written in multiple languages
 - Also a CLI consumer is available to test, bebug Kafka setup
 
 
 * Deafult(Each consumer will receive all the message from the Topic)
 * Different Consumer can subscribe to same Topic
 * Consumer can create scalining group i.e. Consumer Groups
  where each Consumer is assinged to a subset of partitions of a topic
 
 
** How to handle Backpressure?
  * Using Consumer Groups - Dynamically adds or/ remove Consumers
  * Kafka store the messages as per the retention policy


=======================================

Zookeeper?
  A project out of Hadoop
  Centralized service that is highly reliable distributed Coordination to synchronize resources
  
  * Open source project
  * distrubuted coordiantion service
  * synchronization b/w clients
  * Maintains the configuration information
  
 *The Service usually consists of three or five nodes in production quorum


How does Kafka relates to Zookeeper?
  - Brokers use Zookeeper for Clusture management
  - Failure detection and recovery
  - Leader election
  - ACLs
  - Maintaining metadata

====================================

What is more in Kafka - than other middleware integration systems?
  * Publisher/Subscriber messaging system
  * Falut tolerant
  * Data storage as per retention policy
  * Multip consumer (can read the same message) e.g. a slow processing queue, and real-time stream
    consumes messages at different rate
  
  * Each Consumer can maintain offset
  * Highly available and durable
    - Messages are replicated on multiple machines
    - Clusture with help of Zookeeper can handle failures
    
  * Scalable [desinged for scale out] - Each clusture and broker can process huge number of messages
  * Realtime and Batch Consumption

  * Decouple producers and consumers
  * Multi
    . brokers
    . topics
    . Consumers [Pull architecture, each consumers polls a message]
    . Consumer groups [Manages the heartbeat with each consumer]
    
    
  * All the messages are processed by brokers as log messages
  * Utilizes OS page cache to hold recent produced data which can be consumed
  
  * High speed transfer - (A zero copy transfer)
    Data is not written by JVM on heap instead directly transferred to n/w 
    using OS page cache once message has been received from broker
  
  ===================================================
  A sample Kafka commands or CLI:
  
    1. Start Kafka
      
    2. Produce messages
       kafka-console-producer --broker-list HOSTNAME:PORT --topic TOPIC_NAME
       ...
       ^+d to stop typing and send the data
    
    3. Consumer messages
  
      kafka-console-consumer \
    --bootstrap-server HOSTNAME:PORT \
    --from-beginning \
    --topic TOPIC_NAME

      ^+c for stop reading the messages
    
    4. Administer Kafka using Zookeeper
    
     zookeeper-shell NAME
        ls /
      [schema_registry, cluster, controller_epoch, controller, brokers, zookeeper, admin,
      isr_change_notification, consumers, config]


===================================================
  Kafka Logs - a fault tolerant feature with Partition logs in Kafka?
    1. Commit logs-
      Persist the messages sent by consumers on the disk
      This provides the privilege to iterate using Offset
      
      - Producer can write to single partition (provides sequenctional access using commit logs)  
      - Prodcuer can write to multiple partitions
  
  
   2. Offset Logs- That stores index offset for each consumers
   
   3. Timestamp to file offset


============================================

Kafka Replication - fault tolerant?
  * A single partition has been replicated across multiple brokers in clusture
  * Three is the replication factor in production
  
  * Where 1/ 3 nodes is Leader and others are followers
  * All writes are handled by leaders, which has been propagated to followers

  * ISR's (in-sync replicas) which replaces leaders in case of failures
  
 
 Note: One broker is designated as Controller in the entire clusture
  - This broker detects failure and spawn new instances via Zookeeper
  - Selecting new leader from the ISR list
  - Stores leader information and ISR list in Zookeeper
  - Propagate changes to all the brokers (e.g. ISR list or new leader elected)
 
 If Controller failed, then one of other broker is elected as new Controller
 
 
* All reads/writes are done through leaders of the topic paritions

* A single partition has been consumed by single consumer in the Consumer group

========================
Partition strategy for assignment and re-assignment with the Consumer in ConsumerGroups?
  1. Range partition - 
  2. round robin
  
  
  Note: All messages with the same key will got to same Consumer, until there is change due to failure or addition
  
























