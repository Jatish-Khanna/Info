Unknown Error At line:1 eclipse - pom.xml - 
   change the property <maven-jar-plugin.version>3.1.1</maven-jar-plugin.version>
   https://stackoverflow.com/questions/56142369/why-am-i-getting-unknown-error-in-line-1-of-pom-xml

----------------------------------------------

Enable Prometheus

pom.xml
  		<dependency>
			<groupId>org.springframework.boot</groupId>
			<artifactId>spring-boot-starter-actuator</artifactId>
		</dependency>
		<dependency>
			<groupId>io.micrometer</groupId>
			<artifactId>micrometer-core</artifactId>
		</dependency>
		<dependency>
			<groupId>io.micrometer</groupId>
			<artifactId>micrometer-registry-prometheus</artifactId>
		</dependency>
      
 application.yml-- 
management:
  endpoints:
    web:
      exposure:
       include: "*"
  endpoint:
    metrics:
      enabled: true
  prometheus:
      enabled: true
  metrics:
    export:
      prometheus:
      enabled: true
---------------------------------

Kafka interdocker communication:

KAFKA_LISTENERS: LISTENER_HOST://kafka0:29092,LISTENER_INSIDE://localhost:9092
KAFKA_ADVERTISED_LISTENERS: LISTENER_HOST://kafka0:29092,LISTENER_INSIDE://localhost:9092
KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: LISTENER_HOST:PLAINTEXT,LISTENER_INSIDE:PLAINTEXT
KAFKA_INTER_BROKER_LISTENER_NAME: LISTENER_HOST

KAFKA_ADVERTISED_LISTENERS is a comma-separated list of listeners with their the host/ip and port. 
This is the metadata thatâ€™s passed back to clients.

Kafka brokers communicate between themselves, usually on the internal network (e.g. Docker network, AWS VPC, etc). 
To define which listener to use, specify KAFKA_INTER_BROKER_LISTENER_NAME


---------------------------------------

Kafka when hosted on Windows is working fine, with same docker configuration when hosted on linux Message-viewer failed to show messages

Issue:
  ws://<Host>:9021/ws/2.0/<>/consumer?topic=featured_user_event_topic -> From the n/w call http to ws upgrade failed
Error:
  An unknown error has occurred. Check the connection settings

RCA: The upgrade request from HTTP to WebSocket will fail with error 
  Error during WebSocket handshake: Unexpected response code: 503

Solution:
  Microsoft/kafka-proxy-ws another service accepting the websocket connection

------------------------------------------------

Linux server not accepting the input traffic Using public-IP but working using loopback address (localhost, 127.0.0.1)

Issue:  Application was not able to service incoming request using public IP
Error: No
RCA: The traffic has been rejected by Linux server firewall and all the packets were rejected or DROPPED

Solution:
  Note: The user must be sudo or root to perform the action
  iptables -L INPUT // List all the rules
  iptables -L INPUT --line-numbers // List only incoming rules
  iptables -I INPUT -p tcp --dport <10331> -j ACCEPT // Insert the rule to the beginning of the list

  iptables -L INPUT --line-numbers // Verify the traffic is accepted
  

----------------------------------------------------


org.springframework.context.ApplicationContextException: 
Failed to start bean 'org.springframework.kafka.config.internalKafkaListenerEndpointRegistry';
nested exception is org.apache.kafka.common.protocol.types.SchemaException: Error reading field 'correlation_id': 
java.nio.BufferUnderflowException
	at org.springframework.context.support.DefaultLifecycleProcessor.doStart(DefaultLifecycleProcessor.java:185)
	at org.

RCA: Check if the bootstrap-servers defined in application.yml/properties are reachable
  If the server is reachable over the defined port, but that is not being Kafka broker
  - It will fail with the above error

Solution: Either change the host:port combination in the application.yml/properties or 
        Start the Kafka instance at the specific port from which host is sending reply
	
	Mostly, It would have been issue while shutting down the previous instance of application.
	
	// Find the PID bound with process
	netstat /ano | find "9092"
	// Find the process using the port
	tasklist /fi "pid eq 14492"
	
============================================

BROKER Failed:

kafka.zookeeper.ZooKeeperClientTimeoutException: Timed out waiting for connection while in state: CONNECTING
        at kafka.zookeeper.ZooKeeperClient.$anonfun$waitUntilConnected$3(ZooKeeperClient.scala:258)
        at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
        at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:253)
        at kafka.zookeeper.ZooKeeperClient.waitUntilConnected(ZooKeeperClient.scala:254)
        at kafka.zookeeper.ZooKeeperClient.<init>(ZooKeeperClient.scala:112)
        at kafka.zk.KafkaZkClient$.apply(KafkaZkClient.scala:1826)
        at kafka.server.KafkaServer.createZkClient$1(KafkaServer.scala:364)
        at kafka.server.KafkaServer.initZkClient(KafkaServer.scala:387)
        at kafka.server.KafkaServer.startup(KafkaServer.scala:207)
        at io.confluent.support.metrics.SupportedServerStartable.startup(SupportedServerStartable.java:114)
        at io.confluent.support.metrics.SupportedKafka.main(SupportedKafka.java:66)

            

Solution
      KAFKA_ZOOKEEPER_CONNECTION_TIMEOUT_MS: 16000
      
  ===========================================================
  
  
org.springframework.context.ApplicationContextException: Failed to start bean 'org.springframework.kafka.config.internalKafkaListenerEndpointRegistry'; nested exception is org.apache.kafka.common.errors.TimeoutException: Timeout expired while fetching topic metadata
        at org.springframework.context.support.DefaultLifecycleProcessor.doStart(DefaultLifecycleProcessor.java:185)
        at org.springframework.context.support.DefaultLifecycleProcessor.access$200(DefaultLifecycleProcessor.java:53)
        at org.springframework.context.support.DefaultLifecycleProcessor$LifecycleGroup.start(DefaultLifecycleProcessor.java:360)
        at org.springframework.context.support.DefaultLifecycleProcessor.startBeans(DefaultLifecycleProcessor.java:158)
        at org.springframework.context.support.DefaultLifecycleProcessor.onRefresh(DefaultLifecycleProcessor.java:122)
        at org.springframework.context.support.AbstractApplicationContext.finishRefresh(AbstractApplicationContext.java:893)
        at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.finishRefresh(ServletWebServerApplicationContext.java:161)
        at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:552)
        at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.refresh(ServletWebServerApplicationContext.java:140)
        at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:742)
        at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:389)
        at org.springframework.boot.SpringApplication.run(SpringApplication.java:311)
        at org.springframework.boot.SpringApplication.run(SpringApplication.java:1213)
        at org.springframework.boot.SpringApplication.run(SpringApplication.java:1202)
        at com.comcast.ebi.EbiMlaasApplication.main(EbiMlaasApplication.java:37)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        at java.lang.reflect.Method.invoke(Method.java:498)
        at org.springframework.boot.loader.MainMethodRunner.run(MainMethodRunner.java:47)
        at org.springframework.boot.loader.Launcher.launch(Launcher.java:86)
        at org.springframework.boot.loader.Launcher.launch(Launcher.java:50)
        at org.springframework.boot.loader.JarLauncher.main(JarLauncher.java:51)
Caused by: org.apache.kafka.common.errors.TimeoutException: Timeout expired while fetching topic metadata

Root cause:
  The DNS service is not working properly on the Linux machine where application package was installed
  
Reproduce:
  docker exec -it <some-component> sh
  ping <dns-other-component>
    Output: ping failed ... No such service
    
 Solution:
   As the IP address is reachable but DNS service is not working
   A new DNS has been created for the component, by adding extra_hosts - and the DNS resolved to Machine IP
   
   ---
version: '2'
services:
  zookeeper:
    image: confluentinc/cp-zookeeper:5.3.0
    hostname: zookeeper
    container_name: zookeeper
    extra_hosts:
      - "broker:<MACHINE_IP>"
    ports:
      - "2181:2181"
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000

  
==================================
How to pull an image from the enterprise docker repository?
  docker pull registry.blaze.io/<namespace>/<image_name>:version

============================

Hive conncetion failure when Using Kerberos Ticket?

Unknown HS2 problem when communicating with Thrift server.
Error: Could not open client transport with JDBC Uri: 
jdbc:hive2://<HOSTNAME>:10000/default;principal=hive/_HOST@PRINCIPLE_DOMAIN;: Invalid status 21 (state=08S01,code=0)

Command Used - 
!connect jdbc:hive2://<HOSTNAME>:10000/default;principal=hive/_HOST@PRINCIPLE_DOMAIN;

Solution:
  Add missing parameters defines URL:
  
  [beeline]
 !connect jdbc:hive2://<HOSTNAME>:10000/default;principal=hive/_HOST@PRINCIPLE_DOMAIN;saslQop=auth;ssl=true;

OR [beeline]

!connect jdbc:hive2://<HOSTNAME>:10000/default;principal=hive/<HOSTNAME>@PRINCIPLE_DOMAIN;saslQop=auth;ssl=true;

OR Using LDAP [beeline]

!connect jdbc:hive2://<HOSTNAME>:10000/default;user=<LDAP_USER>;password=<LDAP_PASSWORD>;saslQop=auth;ssl=true;

OR [Spring boot + JDBC + Hive]

  private static String driverName = "org.apache.hive.jdbc.HiveDriver";

		Connection con = DriverManager.getConnection(
				"jdbc:hive2://<HOSTNAME>:10000/default;saslQop=auth;ssl=true;",
				"<USER_NAME>", "<PASSWORD>");
				
The trust store has been imported into JRE Keytool

	# To check the content of the keystore, we can use keytool again:
	keytool -list -v -keystore mytruststore.jks

	#Export Self signed certificate into .cer file
	keytool -exportcert -alias <ALIAS_FROM_ABOVE_COMMAND> -keystore mytruststore.jks -file mycertificate.cer

	# (Run As Administrator- to open CMD.exe)
	# Install self-signed certificate into Java JDK CA Certificate key store path
	# to avoid giving certificate path in the client program.
	keytool -import -alias <ALIAS_FROM_ABOVE_COMMAND> -keystore "%JAVA_HOME%\jre\lib\security\cacerts" -file mycertificate.cer

	# List certificates stored in JDK Key store which you have just now imported into JDK Security path.
	keytool -list -keystore "%JAVA_HOME%\jre\lib\security\cacerts
				

OR [Spring Boot + JDBC + Hive + Truststore]

		Connection con = DriverManager.getConnection(
				"jdbc:hive2://<HOSTNAME>:10000/default;saslQop=auth;ssl=true;sslTrustStore=C://certs//squirrel//truststore.jks;trustStorePassword=<TRUST_STORE_PASSWORD>;",
				"<USER_NAME>", "<PASSWORD>");
		Statement stmt = con.createStatement();


Note: saslQop=auth;ssl=true; have been added to resolve the issue




