

Issue with the existing systems?
  1 Limited scalability and availability, where as Kafka is built to scale and be available for the distributed systems
  2 Broker per scenario whereas Kafka provides topics and partitions to handle different sources and distributed systems
  3 Active passive clustering for the existing systems
  4 No backward compatibility with the existing messages and schema
  5 Downtime for maintenance, failures and system upgrades
  6 No backward compability or minimal with the servers and the clients
  7 Tight coupling via synchnoronous communication REST
  8 No handling of backpressure or unavailable consumers, push based mechanism vs Kafka offers Pull based mechanism
  
Why need technology?
  The sources have changes and new technologies for the distributed and scalable system.
  These new systems should adopt to new speed, scale, efficieny like Kafka offers submillisecond latency for the systems
  
What should be the base of new technology?
  1. Event streaming platforms where, you see use cases like IoT always on and sending data
  A loose copuling between the publishers and subscribers
  
Event?
  Something happened now or in the past, any activity performed
  - Events are everywhere e.g. I just typed has produced so many events includes logging, tracking, typing, network call, display
  
 What is paradigm shift?
   A data instead of hosting through static tables or data stores, now becomes events and they are unlimited streams to depict
    the final outcome represents an activity or result
    
    
  
  
Options?
  An event streaming platform, where the architecture remains same as ESB or message queues
  - but there is more it like
 1)
  ESB or messaging systems have lot of options already present in the market
  whereas Event driven we have option of Kafka - community edition and enterprise
 
 2) 


Kafka?
  An event driven integration system for distributed architecture
  It is append only log with all the events generated by source or sources are stored in partition as event in an immutable way.
  It can store data until the space is available or forever
  It handles backpressure well as conumers can consume the way they want, at there speed
  It acts as a integration layers, as events can be consumer by individual consumer or consumer groups maintaining there own offsets
  
  Endorse to build applications in streaming way considering always on and running
  
  Messaging, Storage and processing.
  Supports realtime stream processing
  It also supports fire and forget, EOS, pub/sub, batch based mechanism
  Extreme scale and throughput
  Built for reliability and zero downtime (built for failure)
  High availability
  Rolling upgrades and dynamic configuration changes
  Backward compatibility - A client and server are independent of each other
  
  Coding, scripting, console and REST options are availble to interact with Kafka
  
  Decoupling of clients
    Dumb pipes and smart end points with the back pressure
    It is pull based mechanism
    
  
  Kafka and ESB?
    Kafka has source and sink connetors to connet with existing middle ware infrastructure
    Kafka doesn't work well with legacy systems like Cobol projects and others
    Just a P2P messaging infrastructure with active/passive HA 
    Visual coding for integration components
    
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
