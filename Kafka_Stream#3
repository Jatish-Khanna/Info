Kafka Stream API - 
  It is streaming data API, built on Producer and Consumer. 
  - Supports Stateless, stateful and Windowing processing
  - Supports per record stream processing with millisecond latency
  - A functional level desing is focused instead of Producer and Consumer
  
  * Kafka streams has DSL (Domain specific language)
   - Provides different implementation like Avg, frequency, sum, filter, map, flatMap
   
** Kafka Streams API provides streaming capabilities with-
  Spark Streaming
  Apache storm
  Apache Samza
  
 Note: The streams API doesn't require a clusture of its Own 
   . Can run on a stand-alone machine or multiple-machines
   
 Using streams API reduces the workload on DBMS by efficiently processing data and aggregationf unctions


=================================
What is a Stream?
  An unbounded, continuous real-time flow of  data
 - A consumer doesn't need to request a new record whereas it has been published

: Messages in Stream are in Key/Value pair.

A stream Processor, transforms data in a stream. A processor topology defines the data flow through the stream processorrs

-
 A stream reads a data from the Topic, perform operations and process the data, writes back to Topic

TOPIC -----------> Stream processor --------------> Topic

=================================
Kstreams and KTables?
  A KStream is an abstraction of record stream
  - Each record is an individual event
  
  KTable is an abstraction over changelog stream (a collection of evolving facts)
   - Each record represents "an Update"
   like a compacted topic (a hashmap of Key/value pair if present update)
   
   
 Windowing, Joining and Aggregation?
   Kafka streams API allows us to windows the stream y time
   - A time based buckets
   
  * Aggregate functions is the best operations that can be performed
  * Join operation on different sources
   
  ===================================== 
   
   1. Configuration
     -java.util.Properties
     
     APPLICATION_ID_CONFIG should be unique in the Kafka clusture
     BOOTSTRAP_SERVERS_CONFIG: a list of Kafka brokers to lookup in clusture (3 hostport pair is good approach)
     
     
     Properties properties = new Properties();
     properties.put(StreamConfig.APPLICATION_ID_CONFIG, "Sample-Application");
     properties.put(StreamConfig.BOOTSTRAP_SERVER_CONFIG, "HOSTNAME:PORT");
     ...
     
   
   2. Serializers and Deserializers (Serdes)
     Key Serdes can be different from Value Serdes
     Lot of Serdes are available and custom serdes are available as well.
   
   properties.put(StreamConfig.DEFAULT_KEY_SERDE_CLASS_CONFIG, Serdes.String().getClass()_;
   properties.put(StreamConfig.DEFAULT_VALUE_SERDE_CLASS_CONFIG, Serde.String().getClass());
   
   // Avro serdes are also aviable for Complex types and Custom Serde can be created by implementing the interface
   
   
   3. Process of topology
   StreamBuilder builder = new StreamBuilder();
   KStream<String, String> stream = builder.stream("TOPIC_NAME");
   
   Transformation of data stream can be done using - Aggregation(result:KTable), filtering, mapping functins available for Kstream
   
   These streams are similar to Stream API in Java 8
   
   ---------------------
              Aggregations and Semantics
            ||============================ |
                                           \/
   KStream                                KTable
            ^                              
            |=============================||
              toStream()
   
   
   Streams can be writting to Kafka topic-
      stream.to("TOPIC_NAME");
      
      - Write to Topic and then continue to process the data
      stream.through("TOPIC_NAME").flatMap(...);
   
   This is also Lazy processing, until externally called to start it would lazly wait to evaluate
   ===============================================
   KafkaStream kafkaStreams = new KafkaStreams(builder.build(), properties);
   kafkaStreams.start();
   
   
   this is blocking call, until the stream processing is finished the above operation will wait and block the application processing
   
   -----------------
   Allow application to Gracefully shutdown?
     in response to SIGTERM
     
     Runtime.getRuntime().addShutdownHook(new Thread(stream::close));
     
     After an application has been stopped Kafka transforms any task that is running under this instance 
     to available remaining instances
   
   This is recommended and cleaner way to close the Streams.
   
   
   =========================================
   Managing Kafka Stream applications-
     . Same Kafka stream application under multiple m/c's
     . Kafka clusture will automatically distribute the workload b/w all the nodes/ instances of the applications
     
     . Parallelizing Kafka Streams or KSQL applications improves throughtput and performance
     . It makes application fault tolerant
     . The number of taska in Kafka Streams application may increases with increase in partition count
   
   --------------------
   The architecture of Streams the Scale pointof view-
    . The bottleneck for scale is number of partitions
    . The maximum number of instances can be equal to maximum number of partitions for a Topic
   
   num.standby.replicas (default: 0) Number of standby replicas for each task
   
   The clients manage the standby replicas for streaming application.
   These replicas sync the running copy of stream application and ensures the backup in case of failures
   
   ==================
   How streams manages Stateful applications?
     - Stateful application use stream operations such as aggregation
     - The client keep state in local state stores i.e. RockDB [Key/Value DB]
     - The state is stored locally on the client machine
     - 50-100Mb of memory overhead for the metadata
     - The state is stored in Compacted Kafka Topics
      . If client state store is failed, a recovery point is available
      
    - Using standby copies where No Paritions are allocated to Brokers, helps storing and replicating the state o
    
    
If Client performance is CPU bound, a scale up is the option 
num.stream.threads (Default: 1)

If the client performance is bound by the IO or n/w 
  Scale out is the additional option
  
How Clients use Stream processing impact Utilization of Kafka Cluster
  - Kafka Streams API creates a local state of client and stores that on Kafka Cluster
  
  The more metadata of the client state, the more sync operation are required impacts the performance of Kafka cluster
  However, using kafka streams will result in extra Consumers and n/w bandwidth utilizaation
  
  
  
























