Why Microservices?

  . Simple
  . Reliable
  . Scalable
  . Resilient
  . Faster to develop and deliver
  . Multiple technology stack
  . Multi interfacing
  
  
Why API gateway?

An API Gateway is the element that coordinates and orchestrates how all the requests are processed in a Microservices architecture, and this also includes to the Serverless model.
 An API Gateway includes an HTTP server where routes are associated with a Microservice or with a FaaS function.
 When an API Gateway receives a request, it looks up for the Microservice which can serve the request and delivers it to the relevant part.
 It maps the request parameters to the input arguments of the service or function if necessary, in order to complete the start of the request.
 Then, it gets the result that the function got to the request into an HTTP response and returns it to the original caller.


  . Simple entry point & 
  . Security
  . Dynamic service discovery
  . Circuit breaking
  . Abstracting the overall architecture
  . Traffic control




Cloud native applications-
  . Load balance the instances of single service
  . Are services resillient if application has been failed
  . Benefit of scalability, and how to share the configuration b/w these common instances?
  . How to know where services are hosted on cloud - the port and host name
  . How to avoid duplication of common configuration?
  . how to trace the flow b/w the microservices?


==========================

Solution# to problem - when microservices are scaled, how they should share the common configuration 


          VCS(Git) ---------------> ConfigServer
                                      |||||
                                ==================
                                  Microservice-#1
                                  M-#2
                                  M-#3
                                  ...
                                  M-#n
                                  
     Key takeaways-
      . All the configuration details are stored in git
      . All the microservice connect to config server and load the common configuration
      . Git will also manage microservice specific configuration file (dependent configuration)
        [Create separate properties file for each microservice with name of the 
        file matching the" spring.application.name" of the service]
        
      . SpringCloud dependecy
       <dependency>
        <groupId>org.springframework.cloud</groupId>
        <artifactId>spring-cloud-config-server</artifactId>
       </dependency>
      
      . @EnableConfigServer annotation in the application file of config server
      
      
      --
      Restart all the services and enjoy Solution# - Store and load the configuration from ConfigServer
      
      
  ==============================    

Solution#2 - Load balancing between scaled applications

  - An external loadbalancer can be requested in front of instances
  - The above load balancer decides to f/w request b/w scaled services hosted on machinces is called as Server-side loadbalancing
  
  Issues with Server-side loadbalancing:
    This is single point of failure if load balancer fails then we do not have access to any of instances
    - For multiple such microservices which have multiple instances running a collection of LB's to be maintained
    - Every hop in the n/w increases latency 
    
    
    What can be done?
     How about Client-Side load balancing
      - Here client will decide to whom the quest will be sent to
      - The client side load balancers are usually s/w load balancers
      
      Problems with Client-Loadbalancer?
        - The client is managing another cross-cutting concern of load balancing 
        
        Example- Netflix OSS : Ribbon a client side load balancer
        
    How to do?
      1. Add dependency
        <dependency>
          <groupId>org.springframework.cloud</groupId>
          <artifactId>spring-cloud-starter-ribbon</artifactId>
        </dependency>

      2.Create bean -
        @Bean 
        @LoadBalanced
        public RestTemplate restTemplate() {
          return new RestTemplate();
        }

    3. Add ribbon annotation
      @RibbonClient(name="<CUSTOM_NAME>")

    4. Add properties  
    <CUSTOM_NAME>.ribbon.eureka.enabled=false
    <CUSTOM_NAME>.ribbon.listOfServers=http://localhost:8081,http://localhost:8082
    
    
    5. Request the JSON from object
      List<T> result = restTemplate.getForObject("http://<CUSTOM_NAME>/URI/", List.class);
    

Problems with above method=
    . Hardcoded instance as a part of ribbon list, creates dependency 
    . If one of instances fails then request still goes to instances and it will fail - i.e. NoOpPing strategy
     Solution -
      <CUSTOM_NAME>.default.NFLoadBalancerRuleClassName=com.netflix.loadbalancer.RandomRule
    
==============================================    

Problem#2.B - Service discorvery if in scalable instances we need to add/or remove or update connection details
    . updating each time configuration on multiple microservice is cumbersome
    . If you use Cloud ConfigServer even then we posses issue as new node would only be reflected after each service restart/refresh
    . Each microservice may need a restart
    
    Solution:
      . Register service with the central regirsty once started
      . Provide/store details at central registry
      . The new services are ready to be discovered by clients
      
      Example of Central Service registry:
        . Netflix Eureka
        . Zookeeper
        . Consul
        
        
    How to do it?
      1. Update the details of Euraka or Central regirsty in Git
      2. Spring CloudConfig will be used to load the configuration of regirsty from VCS
      3. While starting microservice, register itself with the Central Registry
      
   Code it--
    1. Create an application with Central regirsty 
      <dependency>
        <groupId>org.springframework.cloud</groupId>
        <artifactId>spring-cloud-starter-eureka-server</artifactId>
      </dependency>


    2. Configure Central registry application-
      spring.application.name=<REGISTRY_NAME>
      server.port=<PORT>
      
      eureka.client.fetch-registry=false
      eureka.client.register-with-eureka=false
      eureka.client.service-url.defaultZone=http://localhost:<PORT>/eureka

    
    3. In the main file, annotate with @EnableDiscoveryServer
    
    
    
    On Clients:
     1. Add the annotation to register with the discovery client
     @EnableDiscoveryClient
     
     2. Access the loadbalanced instance
     
    @Autowired
    private DiscoveryClient discoveryClient;

    @RequestMapping("/service-instances/{applicationName}")
    public List<ServiceInstance> serviceInstancesByApplicationName(
            @PathVariable String applicationName) {
        return this.discoveryClient.getInstances(applicationName);
    }
    
==================
  Problem#2.C - Still we need an iterable to decide whcih instance where request will be sent
      . It can be biased based on programming practise
      
      Solution Use @Loadbalanced rest template along with @EnableDiscoveryClient annotation
      
      
      On client:
       1. Annotate with
       @EnableDiscoveryClient
       @EnableRibbon
       
       2. Access each instance using "spring.application.name" using restTemplate
       
       restTemplate.getForObject("http://<SPRING_APP_NAME>"+"/service/, Service.class);
       
      3. Each instance should have unique instance Id
        eureka.instance.instance-id=${random.value}
      









