Pipelines -
  There are different stages, to filter and transform data
  a) $match
  b) $project
  c) $group

The data flows like packages on assembly line, passing from one stage to next stage
Each pipeline can have many stages to filter and transform data


Structure and Syntax -
  db.<Collection_NAME>.aggregate([{STG_1, STG_2, STG_3 ... STG_N}], <OPTIONS>)
  . Each pipeline can have as many stages as you like
  . Multiple options can be provided, e.g. to use the explain plan of query

E.g.
  db.myCollection.(
      [{
      $match: {
        ...
      }
      },{
        $project: {
          ...
        }
      }
      ], {allowDiskUse: true})

--------------------------

  Different types of Operators Used in aggregation -
   
   Aggregation operators: $match and $project are the aggregation operators
   Query Operators: $in and $gte ..
  System Variable: started with $$ and followed by Uppercase letters, e.g. $$CURRENT
  User variable: started with $$ and followed by lower letters, e.g. $$myVariable

Note:
  Some expression in aggregation pipeline can be used in certain stages
  An aggregation pipeline is an array of Stages

-----------------------------

$match - stage to filter documents in mongo pipeline 

  db.<COLLECTION_NAME>.aggregate(
    [
     {
      $match: {
        ...
      }
     }
    ])

Note:
  $match can be used at any stage of the pipeline
  it can be virtually followed by almost all other aggregation operators [few exceptions]
  
  If we want to use $text operator, $match stage must be the first stage in the pipeline
  $match cannot be used with $where
  $match doesn't have any mechanism for Projection but $find allows us.
  $match cannot use both query operators and aggregation expresions
  
-------------------------------

2) $project - project aggregation operator has wider functionality when compared to $find followed by projection functionality

- Select the fields to be displayed
- Select the fields to be removed
- Drive new fields 
- Reassign existing fields

  db.<COLLECTION_NAME>.aggregate(
    [
     {
      $project: {
        ...
      }
     }
    ])


 . _id fields has to be explicitly removed in case of projection
 * If any fields is explicitly requested to project all the Other fields will be removed from Output but _id field
 * $project can be used as many times in the aggregation pipeline
 
 Example of reassigning a value:
 
   db.<COLLECTION_NAME>.aggregate(
    [
     {
      $project: {
      // Here the value of subdocument will be reassigned/creating a new field
        _id: 0, "newFieldFromSubFields" : "$field.subfield"
      }
     }
    ])


-----------------------------

3) $addFields :  similar to $project with a key difference
  - It adds fields to the documents whereas with project we can selectively remove and retain fields
  
It only allow  to modify existing fields or add new fields in pipeline documents
   db.<COLLECTION_NAME>.aggregate(
    [
     {
      $addFields: {
      // Here the value of subdocument will be reassigned/creating a new field
        "newFieldFromSubFields" : "$field.subfield"
      }
     }
    ])

However, the operation performed is similar to $project but -
  * It won't remove any fields from output
 
 Note: In the above example - newFieldFromSubField will be one additional field in the document
   - With $project, we would have got output with just two fields as _id and newFieldFromSubField
  
-------------------------------

4) $geoNear - to perform geo queries with in the aggregation pipeline
  ** geoNear must be the first stage in the pipeline
  
  - difference with $near is, $near cannot use any special indexes like $text
  - The collection on which aggregation is performed must have one and only one geoIndex
  

   db.<COLLECTION_NAME>.aggregate(
    [
     {
      $geoNear: {
        {
          near : { type : "Point", coordinates : [long, lat]},
          distanceField : "returnColumnWithInRange",
          // Specified true if the index is a 2D sphere else false
          spherical : true
        }
      }
     }
    ])

spherical	boolean	Determines how MongoDB calculates the distance between two points:
limit	number	Optional. The maximum number of documents to return

num	number	Optional. The num option provides the same function as the limit option. 
                      Both define the maximum number of documents to return. 
                      If both options are included, the num value overrides the limit value.

maxDistance	number	Optional. The maximum distance from the center point that the documents 
query	document	Optional. Limits the results to the documents that match the query.

distanceMultiplier	number	Optional. The factor to multiply all distances returned by the query.
uniqueDocs	boolean	Optional. If this value is true, the query returns a matching document once, 

distanceField	string	The output field that contains the calculated distance
includeLocs	string	Optional. This specifies the output field that identifies the location used to calculate the distance.

minDistance	number	Optional. The minimum distance from the center point that the documents can be.
key	string	Optional. Specify the geospatial indexed field to use when calculating the distance.

Note: if Using 2D sphere the distance is returned in meters, 
     if using legacy coordinates the distance is returned in radians

--------------------------------------------

Cusor like Stages -
  a) sort
  b) skip
  c) limit
  d) count

** These stages have a equivalent in our query language as cursor method

Example- 
   db.<COLLECTION_NAME>.find(
   {}, {_id: 0, col1 : 1}).pretty()

above finds all the records and display only col1 in pretty print mode

a) Count the documents - 

db.<COLLECTION_NAME>.find(
   {}, {_id: 0, col1 : 1}).count()

b) skip documents - 

db.<COLLECTION_NAME>.find(
   {}, {_id: 0, col1 : 1}).skip(1).pretty()

c) limit the elements -


db.<COLLECTION_NAME>.find(
   {}, {_id: 0, col1 : 1}).limit(1).pretty()


d) Sort the documents -
  - Default sort order for mongoDB is insertion_sort 

db.<COLLECTION_NAME>.find(
   {}, {_id: 0, col1 : 1}).skip(1).sort({col1 : -1}).pretty()
  
reverse order of col1 data

 ****** The above methods are also available in the form of aggregation operators *******
 
 $limit : { <integer> }
 $skip : { <integer> } 
 $count : { <Name of Column shows the count> } 
 $sort : {<field to sort on : <integer and direction>>}

Example - 

 
   db.<COLLECTION_NAME>.aggregate(
    [
     {
      $project: {
      // Here the value of subdocument will be reassigned/creating a new field
        _id: 0, "newFieldFromSubFields" : "$field.subfield"
      }
     }, {
       $skip : 1
     },
     {
      $limit : 5
     },
     {
      $sort : { "newFieldFromSubField" : -1}
     }
    ])

Note: $sort can take max of 100 MB of RAM 
       Setting allowDiskUse: true, allows for larger sort

-------------------------------------------

4) $sample stage - a set of random documents will be selected from the collection
  
  a) Method-1:
  
  - if size if specified i.e. N
  
  where 
   N <= 5% of the number of document in the Collection and,
   100 <= Total number of documents in the source Collection and,
   $sample is the first stage

Then a pseudo-random cursor will be selected to fecth the required number of documents

b) Method-2 :
  All other conditionos - 
  then in-memory random sort and select the number of documents required from the source collection

Note: The sort has same restriction as of $sort aggregation operator

Example
   db.<COLLECTION_NAME>.aggregate(
    [
     {
      $sample: {
       {
         size: 10
       }
      }
     }
    ])


================================================

2) $group stage - 
    The key component of this stage is _id, all the expressions specified becomes the 
     criteria to categorize and group document together
     
     Note: Grouping on One expression is fundamentally same as using "distinct" command on the documents
     
Example-
  {
    $group : {
      _id : $number
      // This count the documents each time a document matches the expression, a value of 1 be added to calculated value
      newFieldCountDocuments : { $sum : 1}
    }
 }  
  
Example-#2
  To create a new field to group elements based on the size of an array
  
  {
    $group : {
      _id : {
        groupedOnArraySize : {
          $cond : [{$isArray : "$field1"},{$size : "$field1"}, 0]
        }
      },
      // New field to count elements grouped
      newField : { $sum : 1}
    }
  }

Example-#3
  Group all the documents-
  // Below expression is same as counting number of documents in the collection
  
  {
    $group : {
      _id : null,
      count : { $sum : 1}
    }
  }

Note: _id specifies, how the documents should be grouped on
All accumulator expressions can be used on the group field
Group can be used multiple times in the aggregation pipeline
it is good to santize the data begore using the group expression

============================================

3) $project - 
  The accumulator expression that are available in $project are-
   $sum, $min, $max, $avg
   $stdDevPop, $stdDevSam

These expressions will not carry forward and operate across multiple documents

Note: Use $unwind and $group accumulator expression to achive and use values across documents

---------------------------------------

*) $reduce operator
  // to find the max value from the array
  $reduce : {
    input : "$array",
    initialValue : -Infinity,
    in : {
    // $$value refers to the value from the accumulator
    // Find the max value and store in accumulator - this iteration is done over an array
      $cond : [{$gt : ["$$this.field1", "$$value"]}, "$$this.field1", "$$value"]
    }
  }

or the easier way is-
 
   { $max : "$array.field1"}

------------------------------------------------

$unwind - 
  this unwinds an array field, creating a new document for each entry in the array as new field value
  Note: the use case to this is- to group all the documents based on each entry in the array field
  Example - Group all the movies based on the director field,
    Understand the complexity as Each movie can have multiple directors
    Unwind the array directors, and then group based on the name
  
  *) Short form of unwind
   $unwind : "$array"
   
  *) Long form of unwind
  $unwind : {
  // The array to unwind
    path : "",
    // New field name that stores the array index
    includeArrayIndex : "",
    preserveNullAndEmptyArrays : <boolean>
  }
  
  Note: using $unwind on large arrays and values may lead to performance issues
  
----------------------------------------------

$first - to get the first document from the cursor

  Example - 
  $group : {
    _id : "field1"
    // Here a new field is created representing the first value after grouping multiple documents
    newFiel : {$first : "$field2"}
  }

---------------------------------------------

$lookup - 
  A stage to combine information from two collections
  It is effectivly a left outer join in SQL [all document from the left and matching documents from the right]
  
$lookup : {

  from : <collection from which we want to lookup document>,
  localField : <field from the input documents array/single value>,
  foreignField : <field from the documents of "from" collection array/single value>,
  as : <output array field>
}

Note: 
 * From - collection cann't be shared and 
 * must be from the same Database
 * Lookup will perform a strict equivality operation
 * as - will override if the name already exists in the document

------------------------------------------------

$graphLookup - 
  Use cases : Reporting chain, routes, disease taxonmy, social networks, fraud detection
  $graphLookup : {
    from: 
    startWith:
    connectFromField:
    connectToField:
    as:
    maxDepth:
    depthField:
    restrictSearchWithMatch:
  }
  
  Modeling such datasets having relational capabilites can be done using-
  1) Parent reference : E.g. in case of Employee hierarchy, a document pertains a field which references to its parent
  {_id: 2, name :" ...", reports_to: 1}
  {_id: 1, name :" ...", reports_to: 1}
There is always a link b/w entities

Note: Challege with above structure is-
  To fetch complete hierarchy, all the documents must be iterated
  Each time a new request to be initiated for different report_to value
  
   Aggregation operation like GraphLookup-
    with the required arguments and depth control
E.g.
// This snipet gives you from Top to bottom employee hierarchy
  $graphLookup : {
    from : "EmployeeCollection",
    startWith : "$_id",
    connectFromField : "_id",
    connectToField : "reports_to",
    as : "EmployeeHierarchy"
  }

// TO get Employee Hierarchy from Lower level to Top level/root 
  $graphLookup : {
    from : "EmployeeCollection",
    startWith : "$reports_to",
    connectFromField : "reports_to",
    connectToField : "_id",
    as : "Employee Bosses"
  }

2) Reverse Referencing - 
  Each document will have the information of all the direct reports instead of reference back to parent
In this case how will the $graphLookup perform the navigation -
  
  $graphLookup : {
    from : "EmployeeCollection",
    startWith : "$directReports",
    connectFromField : "directReports",
    connectToField : "employeeName",
    as : "EmployeeHierarchy"
  }

Note - using Cross lookup (not self join or lookup with a different collection)
  It is good to use $allowDiskUse, as it may help with memory issues [max allowed upto 100MB per aggregation pipeline]
  ** connectToField - indexing this field may help in retrieving the results with performance benefits
  Sharding Collection is not possible with connectFromCollection.
  $match - before $graphLookup should be relevant to this, to get better performance
  
-----------------------------------------

Facets -
  This is analytical capability that allows user to explore data by applying
    - multiple filters and characterizations
    
  E.g. a user catalog - search a keyword on Linkedin
    - The results can further be filtered by applying 
     - Location, company, Relationship filters known as facets

---------------------------------------------

1) Simple Facets: 
    Example -
    $match : {
      $text : {
        $search : "keyword"
      }
    },
    {
    //This will create a facet by Field, on the list of results from previous stage in pipeline
      $sortByCount :  $field1"
    }
// This will result in two fields
 a) _id : with the value of field1 that all the documents have been grouped based on it
 b) count : the number of documents that match the particular group filter

-----------------------------------------------
$bucket - 
  
  
  Example : 
  $bucket : {
  // Groups document just like _id stage in $group
    groupBy : <Expression>,
    boundaries : [lower, ... upper],
    default : <literal>
    output : {
      output1 : {<Accumulator>},
      ...
      
    }
  }

Note: groupBy - we can only specify one value to match on. We can specify expression that evaluates to two field paths
                but must resolve to one value
      boundaries: lower to upper bound, 
          * values specifies in boundaries must be of same type, with the exception being number values
          * At least two boundaries
          * Infinity can be used for unbounded [buckets]
          * default - specified for less than the minimum value specified, or greater than
                  * it must of same type as specified in boundaries
          * Exception is thrown if the values is not present in range of boundaries, and default is not present
            $switch could not find a matching branch for the input, no default value specified
          
 boundary labels with the count of document that match the expression
output : it like an additional field in the $group stage,
  to give fields any possible name and use accumulator expressions to calculate values
  
  Note: Count is the default accumulator for the bucket stage.
    If any other output: is defined than count will have to be explicitly projected
























