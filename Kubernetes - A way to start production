
What containers brings to Us?
  1) Protability
  2) High boot up time 
  3) Lower resource requirements when compared to VM
  4) Easy deployment 
  5) Software virtualization over h/w virtualization
  6) Isolation 
  7) Easy scalability and orchestration
  
  Upgrades with Zero downtime, Sequentionally, pause, resume, rollback.
  
  Container Orchestration Engine - K8s?
    To automate deploy, scale and manage containerized applications on group of servers
    
      Fault tolerant 
      Availabililty 
      Scalability - in, out, up and down
      Clustering
      Scheduling
      Loadbalancing
      Deployment and rollout or canary

Advanced:
    Service Discovery
    Monitoring 
    Secrets managements

Borg - Propprietry container manager of Google

============================================
Creating A K8s cluster:
  Max. 5000 Nodes per cluster
  - Worker nodes[Minions] are the VMs or physical machines where the actual images are deployed
  - Master - Contoller that supports features for user and worker nodes
  - Pods - In most cases we see one containers per pod but it can have more containers
  - Containers - runtime environments that serve world
  
Master:
  1) API server - gateway of entire cluster, to view and review the metadata though APIs.
    How, kubeclt or UI or other ways to invoke APIs
  
  2) Scheduler - scheduling pods for workers
  
  3) Control manager - 
    Nodes are running, orchestration
  
    a) Node controller
    b) Duplication controller
    c) Service account and Endpoint controller
    d) End point controller
  
  4) etcd - Key/Value database to store the metadata and runtime state of cluster


Worker nodes:
 An VMs or physical server that runs the container on runtime environment E.g. Docker or Rocket[RKT]
 a) Kubelet Agent - node agent to monitor PODS and makesure they are healthy. To restart the nodes
 b) Kube proxy - Distrubted n/w manager across all the nodes, pods, containers. 
 c) Runtime container 
 d) Pod - Each POD contain one or more container.

=============================================

Deployments::
  a) Replicas (Scale in or Out) - defaults:1 - atleast one Pod is running at single point in time.
  b) Upgrade - 
  c) Rollback - 
  d) Scale Up or Down - 
  e) Pause and resume - 

Types:
  1. Recreate - Downtime is allowed, when switcting from V1 to V2
  2. Rolling  update[Default] - Incremental, change to all the Pods
  3. Canary - Gradual shift from V1 to V2
  4. Blue/Green - Both the version are deployed and a traffic switch is done at the LB level.
  
  Sample manifest file:
  
   apiVersion: api/v1
   kind: Deployment
   metadata:
     name: redis
     label:
       app: redis
   spec:
     replicas: 3
     selector:
       matchLabels:
         app: redis  
     
     template:
       metadata:
         labels:
           app: redis

      spec:
        containers:
          - name: redis
            image: redis:latest
            ports:
              - containerPort: 6379

===========================

kubectl create -f redis-deploy.yml
kubectl get deploy // get deplyment
kubectl get rs  // Get replica ser
kubectl get po  // Get pods
kubectl describe deploy redis

1) Using kubectl
kubectl set image deploy redis redis-container=redis:5.0.6 --record // Upgrade with --record to track history
2) Edit deployment file
kubectl edit deploy redis

kubectl rollout status deployment/redis
kubectl get deploy // get deplyment

kubectl rollout history deployment/redis

Rollback:
kubectl rollout undo deployment/redis
kubectl rollout status deployment/redis


Scale up or Down:
  kubectl scale deployment redis --replicas=5
  
  kubectl scale deployment redis --replicas=3

Delete deployment:
kubectl delete -f redis.yml

==========================================================

Handson:

Minikube -> A utility to test Kubernetes as standalone system. Which includes K8s master and Worker nodes
Kubeadm -> A utility to setup K8s cluster in realtime. 

  E.g. 
  
  1. Initialize the cluster master node
   kubeadm init --apiserver-advertise-address $(hostname -i)

kubectl -> Manage the K8s cluster from the command line. Pods, deployments and services
  
Commands:
 create , get
 describe, delete,
 exec, logs
 edit, run
 apply, scale
 
 Types:
 Type -    abbrevation
   pod(s) - po
   deployment(s) - deploy
   replicaset(s) - rs
   replicacontroller(s) - rc
   deamonset(s) - ds
   namespace(s) - ns
   persistvolume(s) - pv
   persistvolumentclaim(s) - pvc
   job(s) - --
   cronjob(s) - --
 
 kubectl [command] [TYPE] [NAME] [flags]

Examples:
  kubectl CREATE -f my-stack.yml[json] # the manifest file can be in JSON or YML format
  
  kubectl CREATE -f <directory> # to read all the files from the directory

=====================
Display resource-

  kubectl get po/pods/pod <name_of_pod>
  kubectl get po/pods/pod <name_of_pod> -o wide # to get wide output with the worker node details
  kubectl get po,deploy         # to display multiple resource types

=========================
Kubectl describe - complete description, state, events of resource 

  kubectl describe po <pod_name>
  kubectl describe nodes <node_name>

========================
kubectl delete - to delete the resources

  kubectl delete -f pod.yml # delete resource created by manifest file
  kubectl delete pods,services -l name=<label_name>      # delete pods and services with label
  kubectl delete pods --all            # to delete all the resources of type=pod
=========================
kubectl exec - to interact with the container

  kubectl exec <pod_name> date  # to exec date utility with pod
  kubectl exec <pod_name> -c <container_name> date    # to interact with specific container in a single pod

  kubectl exec -it <pod_name> /bin/bash  
===============================

kubectl logs --- print logs of container in a pod

  kubectl logs <pod_name>
  kubectl logs <pod_name> -f

=================================

----------------------- Kubenetes Cluster -------------------

 You can bootstrap a cluster as follows:

 1. Initializes cluster master node:

 kubeadm init --apiserver-advertise-address $(hostname -i)


 2. Initialize cluster networking:

 kubectl apply -n kube-system -f \
    "https://cloud.weave.works/k8s/net?k8s-version=$(kubectl version | base64 |tr -d '\n')"

It will install weave network plugin for networking b/w components



  3. Join the worker nodes to the cluster -
  
 You can now join any number of machines by running the following on each node
as root:

  kubeadm join 192.168.0.23:6443 --token agzaoz.173lih2kuhqrpr6x 
  --discovery-token-ca-cert-hash sha256:6db4857e68df5ae8cde614f6b4b5c78e3b02e301993eb25c231a7f3419dd8256

 4. First deployment
 
  kubectl run kubebootcamp --image=gcr.io/google-samples/kubernetes-bootcamp:v1  --port=8080

==========================================

kubeadm init [flag]   // to initialize master
kubeadm join --token [] --discovery-token-ca-cert-hash [] // to initialize the worker node
 kubeadm token [CREATE|DELETE|LIST|GENERATE]
 kubeadm version
 kubeadm upgrade plan [version] [flags]  // upgrade the Kubernetes cluster

=================================

Kubernetes cluster imporve performance - 
  
  swapoff -a
  setenforce 0 OR sed -i 's/enforcing/disabled/g' /etc/selinux/config
  
  ## reboot all nodes
  systemctl start docker 
  systemctl enable docker
  systemctl status docker
  
kubeadm - 
kubelet -
kubectl - 

kubeadm token CREATE --print-join-command  # to print the join command for the worker node.

==================================

Lifecycle of a POD:
  Manifest at Masternode -> Pending [] -> Creating Pod -> Running -> succeeded/Failed 

Note: The pods are replaced with new Pods

======================

Pod Config or Manifest file?


apiVersion: v1
kind: Pod
metadata:
  name: <name_of_object-here-pod>
  labels:
    app: test
    mode: dev

spec:
  containers:
    - name: <name_of_object-here-pod>
      image: redis:latest




====================

apiVersion: #define the version number which Kubernetes version Object belogs to
  Kind is mapped with Version of manifest file

  v1: Pod, ReplicationController, Service
  apps/v1: ReplicaSet, Deployment, DaemonSet
  batch/v1:  Job


metadata:
  labels: help to filter out the pods when executing command
  
  
spec:
  to define the container configuration for a pod
